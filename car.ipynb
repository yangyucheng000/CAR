{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 基于内容自适应重采样(CAR)的学习图像降采样方法\n",
    "\n",
    "CAR算法是一种高效的图像下采样和上采样方法，能够帮助图像数据的存储并减小图像传输所需带宽，同时不损失图像的细节。算法设计了一个重采样网络，用于生成低分辨率图像，同时引入了一个可差分的超分辨率网络来恢复低分辨率图像，通过重构损失来更新整个模型的参数。实验证明，该算法达到了最先进的超分辨率性能。\n",
    "\n",
    "# 模型简介\n",
    "\n",
    "![show_images](images/model.jpg)\n",
    "\n",
    "如上图所示，CAR算法采用ResamplerNet生成下采样图像所需的权重与偏移，ResamplerNet由卷积和残差块组成。得到权重与偏移后，通过Downscaling进行图像下采样，下采样过程由cuda实现，然后将下采样图像通过超分辨率网络恢复，最后将恢复后的图像和原始图像通过L1范数对比，得到重构损失，并更新网络参数。\n",
    "\n",
    "## 数据处理\n",
    "\n",
    "开始实验之前，请确保本地已经安装了Python环境并安装了MindSpore Vision套件。\n",
    "\n",
    "## 数据准备\n",
    "\n",
    "训练数据采用DIV2K中的高清图像，训练集包含800张高清图像，验证集包含100张高清图像。\n",
    "训练集下载地址：http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
    "验证集下载地址：http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_HR.zip\n",
    "请将解压后的数据集放到./datasets/DIV2K/下，文件目录如下所示：\n",
    "\n",
    "```text\n",
    "\n",
    ".datasets/\n",
    "    └── DIV2K\n",
    "            ├── DIV2K_train_HR\n",
    "            |    ├── 0001.png\n",
    "            |    ├── 0002.png\n",
    "            |    ├── ...\n",
    "            ├── DIV2K_valid_HR\n",
    "            |    ├── 000801.png\n",
    "            |    ├── 000802.png\n",
    "            |    ├── ...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import mindspore as ms\n",
    "\n",
    "from mindspore import context, nn, ops, Model\n",
    "from mindspore.dataset import vision\n",
    "\n",
    "# 初始化参数\n",
    "parser = argparse.ArgumentParser(description='Train CAR')\n",
    "parser.add_argument('--image_path', default='./datasets/DIV2K', type=str) #数据集路径\n",
    "parser.add_argument('-j', '--workers', default=1, type=int)\n",
    "parser.add_argument('--device_target', default='GPU', choices=['CPU', 'GPU', 'Ascend'], type=str)\n",
    "parser.add_argument('--end_epoch', default=500, type=int)\n",
    "parser.add_argument('--train_batchsize', default=8, type=int)\n",
    "parser.add_argument('--train_repeat_num', default=1, type=int)\n",
    "parser.add_argument('--train_resize', default=192, type=int)  # 4倍下采样\n",
    "parser.add_argument('--scale', default=4, type=int, help='downscale factor')\n",
    "parser.add_argument('--eval_proid', default=1, type=int)\n",
    "parser.add_argument('--checkpoint_path', default='./checkpoint', type=str)\n",
    "parser.add_argument('--output_dir', type=str, default='./exp_res', help='path to store results')\n",
    "args = parser.parse_known_args()[0]\n",
    "\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=args.device_target, device_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据增强\n",
    "\n",
    "训练过程中，将每张高清图像随机裁剪到192×192(4倍下采样)或96×96(2倍下采样)，训练过程只采用随机水平翻转和随机垂直翻转。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建训练数据集\n",
    "import sys\n",
    "sys.path.append(\"./src\")\n",
    "from process_dataset.dataset import DIV2KHR, build_dataset\n",
    "train_transform = [vision.RandomCrop(args.train_resize),\n",
    "                   vision.RandomHorizontalFlip(),\n",
    "                   vision.RandomVerticalFlip(),\n",
    "                   vision.ToTensor()]\n",
    "\n",
    "train_dataloader = build_dataset(DIV2KHR(args.image_path, \"train\"),\n",
    "                                 batch_size=args.train_batchsize,\n",
    "                                 repeat_num=args.train_repeat_num,\n",
    "                                 shuffle=True,\n",
    "                                 transform=train_transform)\n",
    "step_size = train_dataloader.get_dataset_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n",
    "ResamplerNet网络中使用3x3卷积和LeakyReLU将特征升维到128，然后使用5个残差结构提取特征，最后用两个相同的结构分支计算采样权重和偏移，分支由‘Conv-LeakyReLU’ 对组成，并且将特征维度升至256。超分辨率网络采用EDSR，由32个残差结构组成，每个残差结构的特征维度为256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "\n",
    "from src.model.downsampler import DSN\n",
    "from src.model.edsr import EDSR\n",
    "\n",
    "scale = args.scale\n",
    "kernel_size = 3 * scale + 1\n",
    "\n",
    "# create model\n",
    "kernel_generation_net = DSN(k_size=kernel_size, scale=scale)  # ResamplerNet\n",
    "upscale_net = EDSR(32, 256, scale=scale)    # SRNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下采样过程\n",
    "\n",
    "下采样过程通过cuda编程实现，mindspore采用aot方式添加自定义算子，需要执行以下命令\n",
    "\n",
    "```sh\n",
    "cd codebase/course/application_example/CAR/src/plug_in/adaptive_gridsampler\n",
    "python setup.py\n",
    "```\n",
    "\n",
    "编译完成后，可以生成so文件，即可正常导入下采样算子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.ops as ops\n",
    "from plug_in.adaptive_gridsampler.gridsampler import Downsampler\n",
    "\n",
    "\n",
    "downsampler_net = Downsampler(kernel_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 量化过程\n",
    "\n",
    "下采样后的数据为连续的浮点类型，而一般图像使用0-255的整型数据表示像素值，将浮点类型量化为整型数据的过程是一个不可导的过程，为了能对整个网络端到端的求导，论文中采用soft round函数拟合下采样过程。公式如下：\n",
    "\n",
    "$$\n",
    "round_{soft}(x)=x-α*\\frac{\\sin(2\\pi x)}{2\\pi}\n",
    "$$\n",
    "\n",
    "该函数仅在反向传播时用于求导，计算其导函数可得：\n",
    "\n",
    "$$\n",
    "round_{soft}'(x)=1-α*\\cos(2\\pi x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.block import Quantization\n",
    "\n",
    "quant = Quantization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数\n",
    "\n",
    "论文中采用了三种损失函数，分别是L1loss、offsetloss 和 partial TV loss\n",
    "\n",
    "### L1loss\n",
    "\n",
    "L1loss定义为恢复后的图像和原始图像的L1范数。\n",
    "\n",
    "$$\n",
    "\\frac{1}{N} \\sum_{\\boldsymbol{p} \\in \\mathbf{I}}|\\boldsymbol{p}-\\hat{\\boldsymbol{p}}|\n",
    "$$\n",
    "\n",
    "其中 $\\hat{\\mathbf{I}}$ 表示超分辨率结果, $\\boldsymbol{p}$ 和 $\\hat{\\boldsymbol{p}}$ 分别表示ground-truth和重构像素值, N 为像素点数量和颜色通道的乘积。\n",
    "\n",
    "### offsetloss\n",
    "\n",
    "offsetloss用于保证下采样后的图片仍然有很好的拓扑结构。对于下采样后的每个点，远离采样中心的像素和采样点的相关性更低，通过offsetloss约束偏移矩阵的权重。\n",
    "\n",
    "$$\\sum_{i=0}^{m-1} \\sum_{j=0}^{n-1} \\eta+\\sqrt{\\Delta X_{x, y}(i, j)^{2}+\\Delta Y_{x, y}(i, j)^{2}} \\cdot w(i, j)$$\n",
    "\n",
    "其中$w(i, j) = \\sqrt{\\left(i-\\frac{m}{2}\\right)^{2}+\\left(j-\\frac{n}{2}\\right)^{2}} / \\sqrt{\\frac{m}{2}^{2}+\\frac{n^{2}}{2}}$，(m, n)表示采样中心坐标，(i, j)表示偏移矩阵(i, j)位置的值，$w(i, j)$为(i, j)到(m, n)的距离。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OffsetLoss(nn.Cell):\n",
    "    def __init__(self, kernel_size=13, offsetloss_weight=1.):\n",
    "        super(OffsetLoss, self).__init__()\n",
    "        self.offsetloss_weight = offsetloss_weight # loss 权重\n",
    "        x = ms.numpy.arange(0, kernel_size, dtype=ms.float32)\n",
    "        y = ms.numpy.arange(0, kernel_size, dtype=ms.float32)\n",
    "        x_m, y_m = ops.Meshgrid()((x, y))\n",
    "        self.sqrt = ops.Sqrt()\n",
    "        weight = self.sqrt((x_m-kernel_size/2)**2 + (y_m-kernel_size/2)**2)/kernel_size\n",
    "        self.weight = weight.view(1, kernel_size**2, 1, 1)\n",
    "\n",
    "    def construct(self, offsets_h, offsets_v):\n",
    "        b, _, h, w = offsets_h.shape\n",
    "        loss = self.sqrt(offsets_h * offsets_h + offsets_v * offsets_v)*self.weight\n",
    "        return self.offsetloss_weight*loss.sum()/(h * w * b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### partial TV loss\n",
    "\n",
    "相邻采样核偏移不一致可能导致下采样图像的像素相移，表现为锯齿状，特别是在垂直和水平的尖锐边缘。因此引入 partial TV loss保证偏移的一致性。\n",
    "\n",
    "$$\n",
    "Loss^{TV} = \\sum_{x, y}\\left(\\sum_{i, j}\\left|\\Delta X_{\\cdot, y+1}(i, j)-\\Delta X_{\\cdot, y}(i, j)\\right| \\cdot \\mathbf{K}(i, j) + \\sum_{i, j}\\left|\\Delta Y_{x+1, \\cdot}(i, j)-\\Delta Y_{x, \\cdot}(i, j)\\right| \\cdot \\mathbf{K}(i, j)\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TvLoss(nn.Cell):\n",
    "    def __init__(self, tvloss_weight=1):\n",
    "        super(TvLoss, self).__init__()\n",
    "        self.tvloss_weight = tvloss_weight  # loss 权重\n",
    "        self.abs = ops.Abs()\n",
    "\n",
    "    def construct(self, offsets_h, offsets_v, kernel):\n",
    "        batch, _, _, _ = offsets_h.shape\n",
    "        diff_1 = self.abs(offsets_v[..., 1:] - offsets_v[..., :-1]) * kernel[..., :-1]\n",
    "        diff_2 = self.abs(offsets_h[:, :, 1:, :] - offsets_h[:, :, :-1, :]) * kernel[:, :, :-1, :]\n",
    "        tv_loss = diff_1.sum()+diff_2.sum()\n",
    "        return self.tvloss_weight * tv_loss / batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建训练网络\n",
    "\n",
    "将ResamplerNet，SRNet, 下采样过程, 量化过程和loss组合起来。构建训练网络，初始学习率$10^{−4}$ ,训练500epoch，每100个epoch降低学习率。优化器采用Adam， β1 = 0.9, β2 = 0.999\n",
    ", $\\epsilon$ = 10−6.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetWithLoss(nn.Cell):\n",
    "    def __init__(self, net1, net2, aux_net1, aux_net2, offset, loss1, loss2):\n",
    "        super(NetWithLoss, self).__init__()\n",
    "        self.net1 = net1\n",
    "        self.net2 = net2\n",
    "        self.dsn = aux_net1\n",
    "        self.quant = aux_net2\n",
    "        self.offset_unit = offset\n",
    "        self.tv_loss = loss1\n",
    "        self.offset_loss = loss2\n",
    "        self.l1_loss = nn.L1Loss()\n",
    "\n",
    "    def construct(self, image):\n",
    "        kernels, offsets_h, offsets_v = self.net1(image)\n",
    "        downscaled_img = self.dsn(image, kernels, offsets_h, offsets_v, self.offset_unit)\n",
    "        downscaled_img = self.quant(downscaled_img)\n",
    "        reconstructed_img = self.net2(downscaled_img)\n",
    "        loss1 = self.l1_loss(reconstructed_img, image)\n",
    "        loss2 = self.tv_loss(offsets_h, offsets_v, kernels)\n",
    "        loss3 = self.offset_loss(offsets_h, offsets_v)\n",
    "\n",
    "        return loss1 + loss2 + loss3\n",
    "\n",
    "\n",
    "network = NetWithLoss(kernel_generation_net,\n",
    "                      upscale_net,\n",
    "                      downsampler_net,\n",
    "                      quant,\n",
    "                      scale,\n",
    "                      TvLoss(0.005),\n",
    "                      OffsetLoss(offsetloss_weight=0.001))\n",
    "\n",
    "num_epochs = args.end_epoch\n",
    "total_steps = step_size * num_epochs\n",
    "lr = nn.dynamic_lr.piecewise_constant_lr([int(0.2*total_steps), int(0.4*total_steps),\n",
    "                                          int(0.6*total_steps), int(0.8*total_steps),\n",
    "                                          total_steps],\n",
    "                                         [1e-4, 5e-5, 1e-5, 5e-6, 1e-6])\n",
    "opt_para = list(kernel_generation_net.trainable_params())+list(upscale_net.trainable_params())\n",
    "opt = nn.optim.Adam(opt_para, learning_rate=lr, eps=1e-6)\n",
    "model = Model(network=network, optimizer=opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建评估网络\n",
    "\n",
    "评估网络采用DIV2KHR中验证集的10张图片，由于每张图片的大小不一致，因此测试集的batchsize设置为1。评估网络通过callback调用，并保存网络权重文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from mindspore import ops, Tensor, save_checkpoint\n",
    "from mindspore.train.callback import Callback\n",
    "\n",
    "from src.car_utils.metric import cal_psnr\n",
    "\n",
    "class ValidateCell(nn.Cell):\n",
    "    def __init__(self, net1, net2, aux_net1, aux_net2, scale, offset):\n",
    "        super(ValidateCell, self).__init__()\n",
    "        self.net1 = net1\n",
    "        self.net2 = net2\n",
    "        self.dsn = aux_net1\n",
    "        self.quant = aux_net2\n",
    "        self.offset_unit = offset\n",
    "        self.scale = scale\n",
    "\n",
    "    def construct(self, image):\n",
    "        kernels, offsets_h, offsets_v = self.net1(image)\n",
    "        downscaled_img = self.dsn(image, kernels, offsets_h, offsets_v, self.offset_unit)\n",
    "        downscaled_img = self.quant(downscaled_img)\n",
    "        reconstructed_img = self.net2(downscaled_img)\n",
    "\n",
    "        return downscaled_img, reconstructed_img\n",
    "\n",
    "class SaveCheckpoint(Callback):\n",
    "    def __init__(self, eval_model, ds_eval, scale, save_path, eval_period=1):\n",
    "        \"\"\"init\"\"\"\n",
    "        super(SaveCheckpoint, self).__init__()\n",
    "        self.model = eval_model\n",
    "        self.ds_eval = ds_eval\n",
    "        self.m_psnr = 0.\n",
    "        self.eval_period = eval_period\n",
    "        path = os.path.realpath(save_path)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "        self.save_path = path\n",
    "        self.scale = scale\n",
    "\n",
    "    def epoch_end(self, run_context):\n",
    "        cb_params = run_context.original_args()\n",
    "        cur_epoch = cb_params.cur_epoch_num\n",
    "        scale = self.scale\n",
    "        psnr_list = []\n",
    "        if ((cur_epoch + 1) % self.eval_period) == 0:\n",
    "            print(\"Validating...\")\n",
    "            for i, data in enumerate(self.ds_eval.create_dict_iterator()):\n",
    "                if i > 10:\n",
    "                    break\n",
    "                image = data['image']\n",
    "                _, reconstructed_img = self.model(image)\n",
    "                image = image.asnumpy().transpose(0, 2, 3, 1)\n",
    "                orig_img = np.uint8(image * 255).squeeze()\n",
    "                reconstructed_img = ops.clip_by_value(reconstructed_img, 0, 1) * 255\n",
    "                reconstructed_img = reconstructed_img.asnumpy().transpose(0, 2, 3, 1)\n",
    "                recon_img = np.uint8(reconstructed_img).squeeze()\n",
    "\n",
    "                psnr = cal_psnr(orig_img[scale:-scale, scale:-scale, ...],\n",
    "                                recon_img[scale:-scale, scale:-scale, ...])\n",
    "                psnr_list.append(psnr)\n",
    "            m_psnr = np.mean(psnr_list)\n",
    "            if m_psnr > self.m_psnr:\n",
    "                self.m_psnr = m_psnr\n",
    "                save_path = os.path.join(self.save_path, f\"{self.scale}x\")\n",
    "                if not os.path.exists(save_path):\n",
    "                    os.mkdir(save_path)\n",
    "                net = cb_params.train_network\n",
    "                net.init_parameters_data()\n",
    "                param_dict = OrderedDict()\n",
    "                for _, param in net.parameters_and_names():\n",
    "                    param_dict[param.name] = param\n",
    "                param_kgn = []\n",
    "                param_usn = []\n",
    "                for (key, value) in param_dict.items():\n",
    "                    if \"net1\" in key:\n",
    "                        each_param = {\"name\": key.replace(\"net1.\", \"\")}\n",
    "                        param_data = Tensor(value.data.asnumpy())\n",
    "                        each_param[\"data\"] = param_data\n",
    "                        param_kgn.append(each_param)\n",
    "                    elif \"net2\" in key:\n",
    "                        each_param = {\"name\": key.replace(\"net2.\", \"\")}\n",
    "                        param_data = Tensor(value.data.asnumpy())\n",
    "                        each_param[\"data\"] = param_data\n",
    "                        param_usn.append(each_param)\n",
    "                save_checkpoint(param_kgn, os.path.join(save_path, \"kgn.ckpt\"))  # 将resampler和SRNet的权重分开保存\n",
    "                save_checkpoint(param_usn, os.path.join(save_path, \"usn.ckpt\"))\n",
    "                print(f\"epoce {cur_epoch}, Save model at {self.save_path}, m_psnr for 10 images: {m_psnr}\")\n",
    "            else:\n",
    "                print(f\"epoce {cur_epoch}, m_psnr for 10 images: {m_psnr}\")\n",
    "            print(\"Validating Done.\")\n",
    "\n",
    "    def end(self, run_context):\n",
    "        cb_params = run_context.original_args()\n",
    "        cur_epoch = cb_params.cur_epoch_num\n",
    "        print(f\"Finish training, totally epoches: {cur_epoch}, best psnr: {self.m_psnr}\")\n",
    "\n",
    "eval_network = ValidateCell(kernel_generation_net, upscale_net, downsampler_net, quant, scale, scale)\n",
    "val_dataloader = build_dataset(DIV2KHR(args.image_path, \"valid\"),\n",
    "                               batch_size=1,\n",
    "                               repeat_num=1,\n",
    "                               shuffle=False,\n",
    "                               num_parallel_workers=args.workers)\n",
    "\n",
    "cb_savecheckpoint = SaveCheckpoint(eval_network, val_dataloader, scale, args.checkpoint_path, args.eval_proid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore.train.callback import LossMonitor\n",
    "\n",
    "training = False\n",
    "if training:\n",
    "    print(\"start training..\")\n",
    "    model.train(args.end_epoch, train_dataloader, callbacks=[LossMonitor(), cb_savecheckpoint], dataset_sink_mode=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型评估\n",
    "\n",
    "模型评估采用\"Set5\", \"BSDS100\", \"Set14\", \"Urban100\", \"DIV2KHR\",将解压后的数据集放到./datasets/下，文件目录如下所示：\n",
    "\n",
    "```text\n",
    "\n",
    "        └── datasets\n",
    "             ├── Set5\n",
    "             |    ├── baby.png\n",
    "             |    ├── bird.png\n",
    "             |    ├── ...\n",
    "             ├── Set14\n",
    "             |    ├── baboon.png\n",
    "             |    ├── barbara.png\n",
    "             |    ├── ...\n",
    "             ├── BSDS100\n",
    "             |    ├── 101085.png\n",
    "             |    ├── 101087.png\n",
    "             |    ├── ...\n",
    "             ├── Urban100\n",
    "             |    ├── img_001.png\n",
    "             |    ├── img_002.png\n",
    "             |    ├── ...\n",
    "             └── DIV2K\n",
    "                    ├── DIV2K_train_HR\n",
    "                    |    ├── 0001.png\n",
    "                    |    ├── 0002.png\n",
    "                    |    ├── ...\n",
    "                    ├── DIV2K_valid_HR\n",
    "                    |    ├── 000801.png\n",
    "                    |    ├── 000802.png\n",
    "                    |    ├── ...\n",
    "\n",
    "```\n",
    "\n",
    "权重文件存放在./checkpoint下，目录如下：\n",
    "\n",
    "```text\n",
    "\n",
    "        └── checkpoint\n",
    "             ├── 2x\n",
    "             |    ├── kgn.ckpt\n",
    "             |    ├── usn.ckpt\n",
    "             └── 4x\n",
    "                  ├── kgn.ckpt\n",
    "                  └── usn.ckpt\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating... DIV2KHR.Downscaling x4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [15:37<00:00,  9.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 'DIV2KHR', save results at ./exp_res/DIV2KHR\n",
      "Mean PSNR: 32.68\n",
      "Mean SSIM: 0.8871\n",
      "==============================\n",
      "Validating... BSDS100.Downscaling x4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 'BSDS100', save results at ./exp_res/BSDS100\n",
      "Mean PSNR: 29.49\n",
      "Mean SSIM: 0.8092\n",
      "==============================\n",
      "Validating... Set14.Downscaling x4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:25<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 'Set14', save results at ./exp_res/Set14\n",
      "Mean PSNR: 30.61\n",
      "Mean SSIM: 0.8427\n",
      "==============================\n",
      "Validating... Urban100.Downscaling x4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:41<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 'Urban100', save results at ./exp_res/Urban100\n",
      "Mean PSNR: 29.31\n",
      "Mean SSIM: 0.8704\n",
      "==============================\n",
      "Validating... Set5.Downscaling x4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:07<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 'Set5', save results at ./exp_res/Set5\n",
      "Mean PSNR: 34.17\n",
      "Mean SSIM: 0.9196\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from mindspore import load_checkpoint, load_param_into_net, context\n",
    "from src.car_utils.metric import compute_psnr_ssim, ValidateCell\n",
    "from src.process_dataset.dataset import Set5Test\n",
    "\n",
    "\n",
    "kernel_generation_net = DSN(k_size=kernel_size, scale=scale)\n",
    "upscale_net = EDSR(32, 256, scale=scale)\n",
    "\n",
    "#load checkpoint\n",
    "\n",
    "kgn_dict = load_checkpoint(os.path.join(args.checkpoint_path, f\"{scale}x\", \"kgn.ckpt\"))\n",
    "usn_dict = load_checkpoint(os.path.join(args.checkpoint_path, f\"{scale}x\", \"usn.ckpt\"))\n",
    "load_param_into_net(kernel_generation_net, kgn_dict, strict_load=True)\n",
    "load_param_into_net(upscale_net, usn_dict, strict_load=True)\n",
    "kernel_generation_net.set_train(False)\n",
    "upscale_net.set_train(False)\n",
    "downsampler_net.set_train(False)\n",
    "quant.set_train(False)\n",
    "valid_net = ValidateCell(kernel_generation_net, upscale_net, downsampler_net, quant, scale, scale)\n",
    "\n",
    "#read data\n",
    "if not os.path.exists(args.output_dir):\n",
    "    os.makedirs(args.output_dir)\n",
    "\n",
    "target_dataset = [\"DIV2KHR\", \"BSDS100\", \"Set14\", \"Urban100\", \"Set5\"]\n",
    "\n",
    "for data_type in target_dataset:\n",
    "    if data_type == \"DIV2KHR\":\n",
    "        val_dataloader = build_dataset(DIV2KHR(\"./datasets/DIV2K\", \"valid\"), 1, 1, False) # 由于图片大小不一致，batch_size 设置为1\n",
    "    else:\n",
    "        val_dataloader = build_dataset(Set5Test(\"./datasets/\", data_type), 1, 1, False)\n",
    "\n",
    "    psnr_list = list()\n",
    "    ssim_list = list()\n",
    "    save_dir = os.path.join(args.output_dir, data_type)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    print(f\"Validating... {data_type}.Downscaling x{scale}\")\n",
    "    for i, data in enumerate(tqdm(val_dataloader.create_dict_iterator(), total=val_dataloader.get_dataset_size())):\n",
    "        img = data['image']\n",
    "        downscaled_img, reconstructed_img = valid_net(img)\n",
    "        psnr, ssim = compute_psnr_ssim(img, downscaled_img, reconstructed_img, i, save_dir, scale, True)\n",
    "        psnr_list.append(psnr)\n",
    "        ssim_list.append(ssim)\n",
    "\n",
    "    print(f\"For \\'{data_type}\\', save results at {save_dir}\")\n",
    "    print('Mean PSNR: {0:.2f}'.format(np.mean(psnr_list)))\n",
    "    print('Mean SSIM: {0:.4f}'.format(np.mean(ssim_list)))\n",
    "    print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结果对比\n",
    "\n",
    "与论文中的结果对比，误差均在3%以内\n",
    "![show_images](images/res.jpg)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11c3c5397e9acf866e4a0f989d4b26c65610d75cb1253cd2a96c502d16f5ce98"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ms')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
